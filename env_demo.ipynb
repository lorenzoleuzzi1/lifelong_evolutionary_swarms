{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "import environment \n",
    "importlib.reload(environment)\n",
    "from environment import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot features\n",
    "\n",
    "- 25 cm diameter\n",
    "- compass\n",
    "- 360 vision sensor and object reconition in range 50cm\n",
    "- comunication between others robots\n",
    "- ability to pick up stuff (in they're in the same position of the object)\n",
    "- holonomic motion (every directions)\n",
    "- maximum velocity: 200 cm/s\n",
    "- maximum acceleration: 400 cm/s²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PER_STEP = 1 # a step is seconds\n",
    "ROBOT_SIZE = 25 # in cm (diameter)\n",
    "SENSOR_RANGE = 75 # in cm #TODO change\n",
    "MAX_VELOCITY = 200 # in cm/s\n",
    "VELOCITY = 100 # initial 0 max 200, in cm/s\n",
    "MAX_ACC = 400 # in cm/s^2\n",
    "MAX_DISTANCE = VELOCITY * TIME_PER_STEP # in cm\n",
    "\n",
    "SIMULATION_ROBOT_SIZE = ROBOT_SIZE / ROBOT_SIZE # 1\n",
    "SIMULATION_SENSOR_RANGE = SENSOR_RANGE / ROBOT_SIZE # 3\n",
    "SIMULATION_MAX_DISTANCE = MAX_DISTANCE / ROBOT_SIZE # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in a continuous 2D environment (no physics), a robot possesses the capability to navigate in any direction, covering any distance up to a defined maximum per step. Additionally, the robot can pick up (when underneath) and deposit objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVE = 0\n",
    "PICK_UP = 1\n",
    "PUT_DOWN = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robots are equipped with sensory equipment capable of identifying nearby entities. A \"neighbor\" is characterized by a tuple comprising the type of object, the distance to it, and its relative direction. Accordingly, each robot maintains a list of such tuples for a predefined fixed number of neighboring entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena\n",
    "\n",
    "5m x 5m with robots and colored objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARENA_SIZE = 500 # in cm\n",
    "SIMULATION_ARENA_SIZE = ARENA_SIZE / ROBOT_SIZE # robot size is 1 in the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "List of (color_id, edge). The robots must pick up the objects and deposit them in right position. The deposit area is in an edge of the arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_EDGE = 0\n",
    "RIGHT_EDGE = 1\n",
    "LEFT_EDGE = 2\n",
    "BOTTOM_EDGE = 3\n",
    "RED = 3\n",
    "BLUE = 4\n",
    "GREEN = 5\n",
    "YELLOW = 6\n",
    "PURPLE = 7\n",
    "ORANGE = 8\n",
    "GREY = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_RIGHT_PICKUP = 10\n",
    "REWARD_RIGHT_PUTDOWN = 20\n",
    "REWARD_WRONG_PICKUP = -5\n",
    "REWARD_WRONG_PUTDOWN = -10\n",
    "REWARD_MOVING_RIGHT_DIRECTION = 2\n",
    "REWARD_MOVE = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . \u001b[91mO\u001b[0m . . . .\n",
      ". . . . . . \u001b[0m0\u001b[0m . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . \u001b[0m1\u001b[0m . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . \u001b[91mO\u001b[0m . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . \u001b[0m2\u001b[0m . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . \u001b[94mO\u001b[0m . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neighbors': array([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]),\n",
       " 'carrying': array([-1, -1, -1])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_setting = {\n",
    "    'agents': np.array([[5, 5], [10, 10], [15, 15]], dtype=float),\n",
    "    'blocks': np.array([[4, 16], [13, 5], [16, 4]], dtype=float),\n",
    "    'colors': np.array([RED, RED, BLUE], dtype=int)\n",
    "}\n",
    "env = Environment(objective=[(RED, TOP_EDGE), (BLUE, RIGHT_EDGE)],\n",
    "                   size=SIMULATION_ARENA_SIZE, \n",
    "                   n_agents=3, \n",
    "                   n_blocks=3,\n",
    "                   n_neighbors=3,\n",
    "                   sensor_range=SIMULATION_SENSOR_RANGE,\n",
    "                   sensor_angle=360,\n",
    "                   max_distance_covered_per_step=SIMULATION_MAX_DISTANCE,\n",
    "                   sensitivity=0.5,\n",
    "                   initial_setting=initial_setting)\n",
    "initial_state, _ = env.reset() # Initial state\n",
    "env.print_env()\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . \u001b[91mO\u001b[0m . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . \u001b[0m0\u001b[0m . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . \u001b[0m1\u001b[0m . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . \u001b[91mO\u001b[0m . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . \u001b[94mO\u001b[0m . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . \u001b[0m2\u001b[0m . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "action[0]['action'] = MOVE\n",
    "action[0]['move'] = [3, 0]\n",
    "action[1]['action'] = MOVE\n",
    "action[1]['move'] = [1, 90]\n",
    "action[2]['action'] = MOVE\n",
    "action[2]['move'] = [5, 0]\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "env.print_env()\n",
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about 3000 steps per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021619114875793457, 1.0809557437896729)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(3000):\n",
    "    action = env.action_space.sample()\n",
    "    start = time.time()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    end = time.time()\n",
    "    total_time += end - start\n",
    "total_time / 50, total_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
